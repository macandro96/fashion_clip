{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import statistics as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def read_pkl(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "img_path = 'data/image_features_all.pkl'\n",
    "label_path = 'data/label_features_all.pkl'\n",
    "label_ppt_path = 'data/label_features_prompt_all.pkl'\n",
    "ann_path = '../data/validation.json'\n",
    "label_name_path = '../data/iMat_fashion_2018_label_map_228.csv'\n",
    "one_hot_path = '../data/target_labels.json'\n",
    "\n",
    "image_fts = read_pkl(img_path)\n",
    "label_fts_ = read_pkl(label_path)\n",
    "label_ppt_fts = read_pkl(label_ppt_path)\n",
    "label_map = pd.read_csv(label_name_path)\n",
    "label_map = dict(zip(label_map.labelId, label_map.labelName))\n",
    "one_hot = read_json(one_hot_path)\n",
    "\n",
    "anns = read_json(ann_path)\n",
    "anns = anns['annotations']\n",
    "\n",
    "def get_pred(idx,prompt=False):\n",
    "    img_ft = image_fts[idx]\n",
    "    img_ft = torch.from_numpy(img_ft)\n",
    "    img_ft /= img_ft.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    if prompt:\n",
    "        curr_label_fts = label_ppt_fts\n",
    "    else:\n",
    "        curr_label_fts = label_fts_\n",
    "\n",
    "    label_fts = torch.from_numpy(curr_label_fts)\n",
    "    label_fts /= label_fts.norm(dim=-1, keepdim=True)\n",
    "    pred = img_ft @ label_fts.T\n",
    "    return pred\n",
    "\n",
    "def get_label_names(labels):\n",
    "    label_name = {}\n",
    "    for label in labels:\n",
    "        label_name[label] = label_map[int(label)]\n",
    "    return label_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def probe_img(i=10, prompt=False, verbose=False):\n",
    "    ann = anns[i]\n",
    "\n",
    "    img_id = ann['imageId']\n",
    "    if verbose:\n",
    "        print(f'Prediction for image id : {img_id}')\n",
    "    target = ann['labelId']\n",
    "    tr_map = get_label_names(target)\n",
    "    if verbose:\n",
    "        print(f'targets : {tr_map}')\n",
    "\n",
    "    pred = get_pred(int(img_id),prompt)\n",
    "    a,ids = torch.topk(pred, 8)\n",
    "    ids = [x+1 for x in list(ids.detach().numpy()[0])]\n",
    "    pr_map = get_label_names(ids)\n",
    "    if verbose:\n",
    "        print(f'prediction : {pr_map}')\n",
    "    return target, ids\n",
    "\n",
    "def list_to_oneHot(label_list,num_tar=228,indexed=False):\n",
    "    if not indexed:\n",
    "        label_list = [int(l)-1 for l in label_list]\n",
    "    one_hot = [0]*228\n",
    "    for l in label_list:\n",
    "        one_hot[l] = 1\n",
    "    return one_hot\n",
    "\n",
    "# def f1_score_old(pred_oh, tar_oh):\n",
    "#     p = precision_score(tar_oh, pred_oh, average='micro')\n",
    "#     r = recall_score(tar_oh, pred_oh, average='micro')\n",
    "#     f = f1_score(tar_oh, pred_oh, average='micro')\n",
    "#     print(f'prec: {p}, re:{r}, f1 :{f}')\n",
    "\n",
    "def f1_score_(pred, tar):\n",
    "    tar = [int(x) for x in tar]\n",
    "    def prec(pred,tar):\n",
    "        dem = len(pred)\n",
    "        num = 0\n",
    "        for i in pred:\n",
    "            if i in tar:\n",
    "                num += 1\n",
    "        return num/dem\n",
    "\n",
    "    def rec(pred,tar):\n",
    "        dem = len(tar)\n",
    "        num = 0\n",
    "        for i in pred:\n",
    "            if i in tar:\n",
    "                num += 1\n",
    "        return num/dem\n",
    "\n",
    "    def f1(r,p):\n",
    "        # return 2*p*r/(p+r)\n",
    "        return (2*p*r)/(p+r+np.finfo(float).eps)\n",
    "\n",
    "    p = prec(pred,tar)\n",
    "    r = rec(pred,tar)\n",
    "    f = round(f1(r,p),2)\n",
    "    return p,r,f\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9897/9897 [00:01<00:00, 5848.95it/s]\n"
     ]
    }
   ],
   "source": [
    "precs = []\n",
    "recs = []\n",
    "f1s = []\n",
    "for id in tqdm(range(len(anns))):\n",
    "\n",
    "    try:\n",
    "        tar,pred = probe_img(int(id))\n",
    "        p,r,f = f1_score_(pred,tar)\n",
    "        precs.append(p)\n",
    "        recs.append(r)\n",
    "        f1s.append(f)\n",
    "    except Exception as e:\n",
    "        print(f'{id}:{e}')\n",
    "\n",
    "\n",
    "def get_mean(l):\n",
    "    return np.mean(np.array(l))\n",
    "\n",
    "# print(f'{get_mean(precs)}, {get_mean(recs)},{get_mean(f1s)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1800040416287764, 0.18944891873715883,0.1808103465696676\n"
     ]
    }
   ],
   "source": [
    "print(f'{get_mean(precs)}, {get_mean(recs)},{get_mean(f1s)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.4,\n 0.24,\n 0.5,\n 0.25,\n 0.12,\n 0.25,\n 0.22,\n 0.33,\n 0.13,\n 0.14,\n 0.33,\n 0.11,\n 0.12,\n 0.4,\n 0.15,\n 0.22,\n 0.27,\n 0.38,\n 0.25,\n 0.24,\n 0.38,\n 0.4,\n 0.11,\n 0.22,\n 0.1,\n 0.25,\n 0.14,\n 0.1,\n 0.13,\n 0.27,\n 0.11,\n 0.25,\n 0.15,\n 0.13,\n 0.24,\n 1.0,\n 0.13,\n 0.29,\n 0.33,\n 0.15,\n 0.25,\n 0.27,\n 0.14,\n 1.0,\n 1.0,\n 0.14,\n 0.11,\n 0.17,\n 0.13,\n 0.12,\n 1.0,\n 0.29,\n 0.14,\n 0.25,\n 0.27,\n 0.11,\n 0.1,\n 0.22,\n 0.13,\n 0.15,\n 0.13,\n 0.11,\n 0.24,\n 0.21,\n 0.11,\n 0.13,\n 0.14,\n 0.13,\n 0.15,\n 0.14,\n 0.11,\n 0.13,\n 0.25,\n 0.12,\n 0.29,\n 0.15,\n 0.27,\n 0.25,\n 1.0,\n 0.33,\n 0.11,\n 0.25,\n 0.12,\n 0.4,\n 0.11,\n 1.0,\n 0.12,\n 0.21,\n 0.13,\n 0.29,\n 0.22,\n 0.53,\n 0.11,\n 0.14,\n 0.25,\n 1.0,\n 0.13,\n 1.0,\n 0.14,\n 0.29,\n 0.3,\n 0.31,\n 0.15,\n 1.0,\n 0.11,\n 0.13,\n 0.12,\n 0.12,\n 1.0,\n 0.12,\n 0.13,\n 0.27,\n 0.17,\n 0.13,\n 0.12,\n 0.4,\n 0.12,\n 0.13,\n 0.38,\n 0.22,\n 0.29,\n 0.13,\n 0.24,\n 0.43,\n 0.22,\n 0.25,\n 0.4,\n 0.13,\n 0.12,\n 0.29,\n 0.33,\n 0.33,\n 0.11,\n 0.29,\n 0.29,\n 0.31,\n 1.0,\n 0.25,\n 0.15,\n 0.17,\n 0.13,\n 0.12,\n 0.12,\n 0.25,\n 0.4,\n 0.22,\n 0.24,\n 0.27,\n 0.13,\n 0.3,\n 0.11,\n 0.12,\n 0.11,\n 0.25,\n 0.11,\n 0.4,\n 0.13,\n 0.13,\n 1.0,\n 0.13,\n 0.33,\n 0.12,\n 1.0,\n 0.27,\n 0.11,\n 0.57,\n 0.27,\n 0.29,\n 0.11,\n 0.27,\n 0.14,\n 0.14,\n 0.43,\n 0.25,\n 0.33,\n 0.25,\n 0.38,\n 1.0,\n 0.24,\n 0.14,\n 0.22,\n 0.13,\n 0.08,\n 0.24,\n 1.0,\n 0.2,\n 0.29,\n 0.27,\n 0.29,\n 1.0,\n 0.25,\n 1.0,\n 1.0,\n 0.13,\n 0.4,\n 0.13,\n 0.27,\n 0.12,\n 0.43,\n 0.25,\n 0.13,\n 0.22,\n 0.24,\n 0.27,\n 0.32,\n 0.4,\n 0.12,\n 0.33,\n 0.13,\n 0.14,\n 1.0,\n 0.14,\n 1.0,\n 0.14,\n 0.15,\n 0.21,\n 0.13,\n 0.35,\n 0.27,\n 0.12,\n 1.0,\n 0.1,\n 1.0,\n 1.0,\n 0.12,\n 0.24,\n 0.12,\n 0.22,\n 0.25,\n 0.29,\n 0.13,\n 0.25,\n 0.12,\n 0.14,\n 1.0,\n 1.0,\n 0.22,\n 0.25,\n 1.0,\n 0.13,\n 0.11,\n 0.13,\n 1.0,\n 0.14,\n 0.22,\n 0.24,\n 0.12,\n 0.27,\n 0.25,\n 0.13,\n 1.0,\n 0.25,\n 0.13,\n 0.22,\n 0.4,\n 0.38,\n 0.27,\n 0.14,\n 0.25,\n 0.29,\n 1.0,\n 0.13,\n 0.13,\n 0.13,\n 1.0,\n 0.13,\n 0.4,\n 1.0,\n 0.13,\n 0.14,\n 0.24,\n 0.14,\n 1.0,\n 0.12,\n 0.25,\n 0.1,\n 0.14,\n 0.31,\n 0.29,\n 0.13,\n 1.0,\n 0.24,\n 0.31,\n 0.38,\n 0.11,\n 0.21,\n 0.13,\n 0.13,\n 0.38,\n 0.24,\n 0.14,\n 0.29,\n 0.27,\n 0.35,\n 0.27,\n 1.0,\n 0.12,\n 0.27,\n 0.25,\n 0.33,\n 0.13,\n 0.27,\n 0.12,\n 1.0,\n 0.22,\n 0.13,\n 0.13,\n 0.13,\n 0.33,\n 0.27,\n 0.24,\n 0.22,\n 0.31,\n 0.38,\n 1.0,\n 0.14,\n 0.38,\n 0.13,\n 0.27,\n 0.13,\n 0.27,\n 0.35,\n 0.11,\n 0.29,\n 0.25,\n 0.12,\n 0.14,\n 0.13,\n 0.13,\n 0.11,\n 0.25,\n 0.13,\n 0.13,\n 0.13,\n 0.14,\n 0.22,\n 0.12,\n 1.0,\n 0.33,\n 0.29,\n 0.15,\n 0.22,\n 0.15,\n 0.11,\n 0.13,\n 0.15,\n 1.0,\n 0.2,\n 0.13,\n 0.22,\n 0.32,\n 0.27,\n 0.11,\n 1.0,\n 1.0,\n 0.31,\n 0.13,\n 0.27,\n 0.11,\n 1.0,\n 0.4,\n 0.13,\n 0.11,\n 0.4,\n 0.43,\n 0.29,\n 0.35,\n 1.0,\n 0.13,\n 0.12,\n 0.13,\n 0.27,\n 0.38,\n 0.12,\n 0.13,\n 0.13,\n 0.13,\n 0.14,\n 0.11,\n 0.24,\n 0.14,\n 1.0,\n 0.43,\n 0.27,\n 0.38,\n 0.13,\n 0.38,\n 0.17,\n 0.25,\n 0.11,\n 0.35,\n 0.15,\n 0.38,\n 0.11,\n 0.15,\n 0.35,\n 0.4,\n 1.0,\n 1.0,\n 0.24,\n 1.0,\n 0.13,\n 0.13,\n 0.4,\n 0.38,\n 0.12,\n 1.0,\n 0.27,\n 0.53,\n 0.24,\n 0.33,\n 0.13,\n 0.14,\n 0.29,\n 0.29,\n 0.25,\n 0.31,\n 0.13,\n 0.13,\n 0.35,\n 0.13,\n 1.0,\n 0.35,\n 0.29,\n 0.13,\n 1.0,\n 0.13,\n 0.14,\n 0.12,\n 0.13,\n 0.24,\n 0.13,\n 0.27,\n 0.13,\n 0.14,\n 0.2,\n 0.12,\n 0.42,\n 0.13,\n 0.15,\n 0.29,\n 1.0,\n 0.12,\n 0.13,\n 1.0,\n 0.4,\n 1.0,\n 1.0,\n 0.12,\n 0.13,\n 0.33,\n 0.15,\n 0.24,\n 0.17,\n 0.4,\n 0.15,\n 0.29,\n 0.13,\n 0.24,\n 0.27,\n 0.13,\n 1.0,\n 0.38,\n 1.0,\n 0.25,\n 0.27,\n 0.29,\n 0.13,\n 0.13,\n 0.22,\n 1.0,\n 0.25,\n 0.13,\n 0.29,\n 0.13,\n 1.0,\n 0.12,\n 0.27,\n 0.11,\n 0.29,\n 0.22,\n 0.14,\n 1.0,\n 0.27,\n 0.38,\n 0.12,\n 0.24,\n 1.0,\n 0.13,\n 0.11,\n 1.0,\n 0.33,\n 0.13,\n 0.22,\n 0.43,\n 0.11,\n 0.3,\n 0.13,\n 0.13,\n 0.38,\n 1.0,\n 0.33,\n 0.13,\n 0.25,\n 0.13,\n 0.21,\n 1.0,\n 0.17,\n 0.24,\n 0.13,\n 0.25,\n 0.25,\n 0.4,\n 0.14,\n 0.14,\n 0.24,\n 0.24,\n 0.11,\n 0.14,\n 0.4,\n 0.25,\n 0.4,\n 0.24,\n 0.13,\n 0.13,\n 0.14,\n 0.17,\n 0.13,\n 0.13,\n 0.24,\n 0.25,\n 0.27,\n 0.14,\n 0.25,\n 0.27,\n 0.25,\n 0.4,\n 0.13,\n 0.22,\n 1.0,\n 0.11,\n 0.32,\n 0.11,\n 0.22,\n 0.12,\n 1.0,\n 0.13,\n 0.12,\n 0.13,\n 0.5,\n 0.1,\n 0.11,\n 1.0,\n 0.1,\n 0.13,\n 0.35,\n 0.29,\n 0.32,\n 0.44,\n 0.24,\n 0.27,\n 0.27,\n 1.0,\n 1.0,\n 0.24,\n 0.46,\n 0.12,\n 0.25,\n 0.17,\n 1.0,\n 0.14,\n 0.25,\n 0.12,\n 0.27,\n 0.25,\n 0.11,\n 0.11,\n 0.4,\n 0.29,\n 0.11,\n 0.35,\n 0.33,\n 0.13,\n 0.31,\n 0.14,\n 0.13,\n 0.38,\n 0.33,\n 0.12,\n 0.35,\n 0.25,\n 0.13,\n 0.13,\n 0.13,\n 0.19,\n 0.12,\n 0.35,\n 0.27,\n 0.13,\n 0.12,\n 0.13,\n 0.13,\n 0.25,\n 0.13,\n 1.0,\n 1.0,\n 0.13,\n 0.11,\n 0.13,\n 0.14,\n 0.13,\n 0.13,\n 0.11,\n 0.27,\n 0.35,\n 0.13,\n 0.12,\n 0.24,\n 0.25,\n 1.0,\n 0.25,\n 1.0,\n 0.12,\n 1.0,\n 0.35,\n 0.25,\n 0.13,\n 1.0,\n 1.0,\n 0.29,\n 0.33,\n 0.22,\n 0.13,\n 0.29,\n 0.4,\n 1.0,\n 0.4,\n 0.11,\n 0.27,\n 0.38,\n 0.11,\n 0.22,\n 0.13,\n 1.0,\n 0.25,\n 0.13,\n 0.11,\n 0.14,\n 1.0,\n 0.11,\n 0.22,\n 0.25,\n 0.25,\n 0.11,\n 0.15,\n 0.14,\n 0.22,\n 0.33,\n 0.12,\n 0.13,\n 0.22,\n 0.13,\n 0.27,\n 0.21,\n 0.15,\n 0.24,\n 0.25,\n 0.13,\n 0.13,\n 0.29,\n 0.14,\n 0.12,\n 0.27,\n 1.0,\n 0.25,\n 0.13,\n 0.25,\n 0.25,\n 0.25,\n 0.13,\n 0.13,\n 0.29,\n 0.25,\n 1.0,\n 0.38,\n 0.13,\n 0.15,\n 0.1,\n 0.11,\n 0.38,\n 0.25,\n 0.14,\n 0.12,\n 0.14,\n 0.15,\n 0.13,\n 0.35,\n 0.5,\n 0.11,\n 0.29,\n 0.25,\n 0.35,\n 0.38,\n 0.12,\n 0.13,\n 0.13,\n 0.25,\n 0.29,\n 1.0,\n 0.12,\n 0.27,\n 0.11,\n 0.33,\n 0.25,\n 0.14,\n 0.27,\n 0.13,\n 1.0,\n 0.2,\n 0.22,\n 0.13,\n 0.15,\n 0.43,\n 0.25,\n 0.14,\n 0.13,\n 0.09,\n 0.11,\n 0.29,\n 0.22,\n 0.17,\n 0.13,\n 0.33,\n 0.13,\n 0.1,\n 0.24,\n 0.15,\n 0.13,\n 0.15,\n 0.4,\n 0.13,\n 0.24,\n 0.24,\n 0.13,\n 0.11,\n 0.11,\n 0.11,\n 0.13,\n 0.24,\n 0.11,\n 0.13,\n 0.11,\n 0.18,\n 0.35,\n 0.38,\n 0.13,\n 0.11,\n 0.27,\n 0.27,\n 0.11,\n 0.12,\n 0.21,\n 1.0,\n 0.11,\n 0.1,\n 0.24,\n 0.13,\n 0.22,\n 0.14,\n 0.33,\n 0.13,\n 0.13,\n 0.24,\n 0.21,\n 0.14,\n 0.13,\n 0.24,\n 0.27,\n 1.0,\n 0.11,\n 0.29,\n 0.13,\n 0.24,\n 0.24,\n 0.27,\n 0.53,\n 0.21,\n 0.14,\n 1.0,\n 0.25,\n 0.35,\n 0.35,\n 0.24,\n 0.13,\n 0.4,\n 0.1,\n 1.0,\n 0.33,\n 1.0,\n 0.12,\n 0.1,\n 1.0,\n 0.14,\n 1.0,\n 0.33,\n 0.13,\n 1.0,\n 0.38,\n 0.38,\n 0.38,\n 0.13,\n 0.22,\n 0.38,\n 0.24,\n 0.22,\n 0.24,\n 1.0,\n 0.47,\n 0.11,\n 0.12,\n 0.12,\n 0.38,\n 0.21,\n 0.11,\n 1.0,\n 0.17,\n 0.14,\n 0.25,\n 0.13,\n 0.43,\n 0.22,\n 1.0,\n 0.24,\n 0.13,\n 0.12,\n 1.0,\n 0.22,\n 0.22,\n 0.12,\n 0.24,\n 0.12,\n 0.25,\n 0.12,\n 0.24,\n 0.13,\n 0.57,\n 0.4,\n 0.33,\n 0.13,\n 0.2,\n 0.27,\n 0.13,\n 0.24,\n 0.31,\n 0.13,\n 0.32,\n 0.27,\n 0.13,\n 0.13,\n 0.17,\n 0.17,\n 1.0,\n 0.12,\n 1.0,\n 0.13,\n 0.15,\n 0.12,\n 0.57,\n 0.15,\n 0.29,\n 1.0,\n 0.11,\n 0.24,\n 0.21,\n 0.13,\n 0.27,\n 0.12,\n 0.13,\n 0.25,\n 0.13,\n 0.32,\n 0.27,\n 0.17,\n 0.27,\n 0.13,\n 0.13,\n 0.13,\n 0.13,\n 0.33,\n 0.29,\n 0.15,\n 0.24,\n 0.25,\n 1.0,\n 0.5,\n 0.4,\n 0.11,\n 0.13,\n 1.0,\n 0.11,\n 0.24,\n 1.0,\n 0.29,\n 0.13,\n 1.0,\n 0.14,\n 0.38,\n 0.43,\n 0.21,\n 0.27,\n 0.13,\n 0.2,\n 0.35,\n 0.12,\n 0.35,\n 0.38,\n 1.0,\n 0.13,\n 0.4,\n 0.13,\n 0.35,\n 0.27,\n 0.21,\n 0.27,\n 0.13,\n 0.35,\n 0.33,\n 0.25,\n 0.4,\n 0.1,\n 0.25,\n 0.24,\n 0.12,\n 0.14,\n 0.35,\n 0.13,\n 0.14,\n 0.13,\n 0.21,\n 0.13,\n 0.4,\n 0.24,\n 0.27,\n 1.0,\n 0.14,\n 0.13,\n 0.14,\n 0.27,\n 0.22,\n 0.24,\n 0.13,\n 0.11,\n 0.1,\n 1.0,\n 0.33,\n 0.13,\n 0.1,\n 0.22,\n 0.13,\n 0.17,\n 0.25,\n 1.0,\n 0.38,\n 0.15,\n 0.25,\n 0.27,\n 0.27,\n 1.0,\n 0.24,\n 0.15,\n 0.25,\n 0.13,\n 0.13,\n 0.25,\n 0.11,\n 0.25,\n 0.13,\n 0.32,\n 0.21,\n 0.33,\n 0.29,\n 0.12,\n 0.12,\n 0.25,\n 0.11,\n 0.29,\n 0.32,\n 0.29,\n 0.12,\n 0.12,\n 0.14,\n 0.29,\n 0.2,\n 1.0,\n 0.22,\n 0.27,\n 0.35,\n 0.25,\n 1.0,\n 0.25,\n ...]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1s\n",
    "# stats.mean(f1s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}